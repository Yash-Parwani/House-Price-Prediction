# -*- coding: utf-8 -*-
"""RandomForest with GridSearchCV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YTqxSxPrVK790Cep7V2LzYL-nXten6OA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score,accuracy_score

# Load the dataset
df = pd.read_csv('new.csv',encoding='ISO-8859-1')

# Remove unnecessary columns
df = df.drop(['url','id','tradeTime', 'DOM'], axis=1)

# Remove rows with missing values
df = df.dropna()

# remove the rows with 'Î´Öª' in the constructionTime column
df = df[df['constructionTime'].apply(lambda x: str(x).isdigit())]

# Remove rows with outlier values
df = df[(df['price'] > 10000) & (df['price'] < 1000000)]

# Convert categorical variables to numerical variables
df = pd.get_dummies(df, columns=['district', 'floor'])

# Split dataset into training and testing sets
X = df.drop(['price'], axis=1)
y = df['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Hyperparameter tuning
from sklearn.model_selection import GridSearchCV
params = {'n_estimators': [50, 100, 150, 200, 250],
          'max_depth': [5, 10, 15, 20, 25],
          'min_samples_leaf': [1, 2, 4, 6, 8]}
rf = RandomForestRegressor(random_state=42)
gs = GridSearchCV(rf, params, cv=5)
gs.fit(X_train, y_train)

# Build Random Forest model
model = RandomForestRegressor(n_estimators=gs.best_params_['n_estimators'],
                               max_depth=gs.best_params_['max_depth'],
                               min_samples_leaf=gs.best_params_['min_samples_leaf'],
                               random_state=42)
model.fit(X_train, y_train)

# Make predictions on testing set
y_pred = model.predict(X_test)

# Evaluate model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
accuracy = rf.score(X_test, y_test)
print("Mean Squared Error: {:.2f}".format(mse))
print("R2 Score: {:.2f}".format(r2))
print("Accuracy score:", accuracy)
# Plot feature importances
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
features = X.columns
plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.bar(range(X.shape[1]), importances[indices])
plt.xticks(range(X.shape[1]), features[indices], rotation=90)
plt.show()